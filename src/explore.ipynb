{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.feature_selection import SelectKBest, chi2\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import *\n",
                "from imblearn.metrics import specificity_score\n",
                "from warnings import simplefilter\n",
                "from pickle import dump\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We need to perform an EDA before modeling, in this exercise I will cover only the basics since the algorithm is the main point."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Collect the data "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['no', 'yes'], dtype=object)"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv\", sep= \";\")\n",
                "\n",
                "all_data[\"y\"].unique()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now delete all possible duplicates in this dataset, in case there are. Also, obtain the null values and information as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 41176 entries, 0 to 41175\n",
                        "Data columns (total 21 columns):\n",
                        " #   Column          Non-Null Count  Dtype  \n",
                        "---  ------          --------------  -----  \n",
                        " 0   age             41176 non-null  int64  \n",
                        " 1   job             41176 non-null  object \n",
                        " 2   marital         41176 non-null  object \n",
                        " 3   education       41176 non-null  object \n",
                        " 4   default         41176 non-null  object \n",
                        " 5   housing         41176 non-null  object \n",
                        " 6   loan            41176 non-null  object \n",
                        " 7   contact         41176 non-null  object \n",
                        " 8   month           41176 non-null  object \n",
                        " 9   day_of_week     41176 non-null  object \n",
                        " 10  duration        41176 non-null  int64  \n",
                        " 11  campaign        41176 non-null  int64  \n",
                        " 12  pdays           41176 non-null  int64  \n",
                        " 13  previous        41176 non-null  int64  \n",
                        " 14  poutcome        41176 non-null  object \n",
                        " 15  emp.var.rate    41176 non-null  float64\n",
                        " 16  cons.price.idx  41176 non-null  float64\n",
                        " 17  cons.conf.idx   41176 non-null  float64\n",
                        " 18  euribor3m       41176 non-null  float64\n",
                        " 19  nr.employed     41176 non-null  float64\n",
                        " 20  y               41176 non-null  object \n",
                        "dtypes: float64(5), int64(5), object(11)\n",
                        "memory usage: 6.6+ MB\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(41176, 21)"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_data = all_data.drop_duplicates().reset_index(drop= True)\n",
                "\n",
                "all_data.info()\n",
                "all_data.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There aren't any null values but some duplicates, in this case, 12 duplicates.\n",
                "\n",
                "Also, with the .info method we can know that there aren't any null values in this dataset.\n",
                "\n",
                "We need to also factorize all the categorical variables and create a new dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 41176 entries, 0 to 41175\n",
                        "Data columns (total 21 columns):\n",
                        " #   Column            Non-Null Count  Dtype  \n",
                        "---  ------            --------------  -----  \n",
                        " 0   job_fact          41176 non-null  int64  \n",
                        " 1   marital_fact      41176 non-null  int64  \n",
                        " 2   education_fact    41176 non-null  int64  \n",
                        " 3   default_fact      41176 non-null  int64  \n",
                        " 4   housing_fact      41176 non-null  int64  \n",
                        " 5   loan_fact         41176 non-null  int64  \n",
                        " 6   contact_fact      41176 non-null  int64  \n",
                        " 7   month_fact        41176 non-null  int64  \n",
                        " 8   day_of_week_fact  41176 non-null  int64  \n",
                        " 9   poutcome_fact     41176 non-null  int64  \n",
                        " 10  age               41176 non-null  int64  \n",
                        " 11  duration          41176 non-null  int64  \n",
                        " 12  campaign          41176 non-null  int64  \n",
                        " 13  pdays             41176 non-null  int64  \n",
                        " 14  previous          41176 non-null  int64  \n",
                        " 15  emp.var.rate      41176 non-null  float64\n",
                        " 16  cons.price.idx    41176 non-null  float64\n",
                        " 17  cons.conf.idx     41176 non-null  float64\n",
                        " 18  euribor3m         41176 non-null  float64\n",
                        " 19  nr.employed       41176 non-null  float64\n",
                        " 20  y_fact            41176 non-null  int64  \n",
                        "dtypes: float64(5), int64(16)\n",
                        "memory usage: 6.6 MB\n"
                    ]
                }
            ],
            "source": [
                "#Factorize categorical variables in a new dataframe\n",
                "all_data[\"job_fact\"] = pd.factorize(all_data[\"job\"])[0]\n",
                "all_data[\"marital_fact\"] = pd.factorize(all_data[\"marital\"])[0]\n",
                "all_data[\"education_fact\"] = pd.factorize(all_data[\"education\"])[0]\n",
                "all_data[\"contact_fact\"] = pd.factorize(all_data[\"contact\"])[0]\n",
                "\n",
                "\n",
                "#For default, housing and loan as it's yes, no or unknown\n",
                "def_house_loan_map = {\"no\": 0, \"yes\": 1, \"unknown\": 2}\n",
                "\n",
                "#Apply the previous dictionary to map those variables\n",
                "all_data[\"housing_fact\"] = all_data[\"housing\"].map(def_house_loan_map)\n",
                "all_data[\"default_fact\"] = all_data[\"default\"].map(def_house_loan_map)\n",
                "all_data[\"loan_fact\"] = all_data[\"loan\"].map(def_house_loan_map)\n",
                "\n",
                "#For month and days of the week we apply the same method but assigning a number to each day or month\n",
                "months_map = {'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'oct': 10, 'nov': 11, 'dec': 12, 'mar': 3, 'apr': 4, 'sep': 9} #Applying only to the months that appear in the dataset (using all_data[\"month\"].unique() to know that)\n",
                "days_map ={'mon': 1, 'tue': 2, 'wed': 3, 'thu': 4, 'fri': 5} #Applying only to the days that appear in the dataset (using all_data[\"day_of_week\"].unique() to know that)\n",
                "\n",
                "#Apply the previous dictionary to map those variables\n",
                "all_data[\"month_fact\"] = all_data[\"month\"].map(months_map)\n",
                "all_data[\"day_of_week_fact\"] = all_data[\"day_of_week\"].map(days_map)\n",
                "\n",
                "#For outcome variable\n",
                "pout_map = {\"failure\": 0, \"success\": 1, \"nonexistent\": 2}\n",
                "all_data[\"poutcome_fact\"] = all_data[\"poutcome\"].map(pout_map)\n",
                "\n",
                "#For \"y\" variable, same as default, housing and loan except there is no unknown possibility\n",
                "y_map = {\"no\": 0, \"yes\": 1}\n",
                "all_data[\"y_fact\"] = all_data[\"y\"].map(y_map)\n",
                "\n",
                "#Saving the new variables into a list to create a new dataframe with the factorize variables\n",
                "num_variables = [\"job_fact\", \"marital_fact\", \"education_fact\", \"default_fact\", \"housing_fact\", \"loan_fact\", \"contact_fact\", \"month_fact\", \"day_of_week_fact\", \"poutcome_fact\",\n",
                "                 \"age\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\", \"y_fact\"]\n",
                "\n",
                "fact_data = pd.DataFrame(all_data, index = all_data.index, columns = num_variables)\n",
                "\n",
                "fact_data.info()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Divide the new dataset into train and test, the scale all the data based on train variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = fact_data.drop([\"y_fact\"], axis= 1) #Independant variables\n",
                "y = fact_data[\"y_fact\"]# Dependant variables, target\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42) #Random state controls how many shuffles is applied to the data before spliting. It's the same number to replicate the same experiment\n",
                "\n",
                "\n",
                "#Create the scaler\n",
                "scaler = MinMaxScaler()\n",
                "\n",
                "#Train the scaler with the train variables\n",
                "scaler.fit(X_train)\n",
                "\n",
                "#Transform train and test using the scaler\n",
                "X_train_scaled = pd.DataFrame(scaler.transform(X_train), index= X_train.index, columns= X_train.columns)\n",
                "X_test_scaled = pd.DataFrame(scaler.transform(X_test), index= X_test.index, columns= X_test.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Feature selection with SelectKBest using a chi2 statistical method"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "#We create the selection model, in this case k is the number of features to be selected and chi2 the method used to determine wich are the best features to include\n",
                "selection_model = SelectKBest(chi2, k = 5)\n",
                "\n",
                "#Fit the model with both X_train and y_train\n",
                "selection_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "#Gets an array of the features selected\n",
                "ix = selection_model.get_support()\n",
                "\n",
                "#With ix we convert that array information into two new datasets that contain the features selected\n",
                "X_train_features = pd.DataFrame(selection_model.transform(X_train_scaled), columns = X_train_scaled.columns.values[ix])\n",
                "X_test_features = pd.DataFrame(selection_model.transform(X_test_scaled), columns = X_test_scaled.columns.values[ix])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save the new data to proceed with the exercise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_features[\"y_fact\"] = list(y_train)\n",
                "X_test_features[\"y_fact\"] = list(y_test)\n",
                "X_train_features.to_csv(\"../data/processed/clean_train.csv\", index = False)\n",
                "X_test_features.to_csv(\"../data/processed/clean_test.csv\", index = False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we continue with the Logistic Regression Model. For that we need to read the data that we saved later and then divide it again into X and y, those are going to be our independant and dependant data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Read the data saved\n",
                "train_data = pd.read_csv(\"../data/processed/clean_train.csv\")\n",
                "test_data = pd.read_csv(\"../data/processed/clean_test.csv\")\n",
                "\n",
                "#Divide into train and test for each independant and dependant variables\n",
                "X_train = train_data.drop([\"y_fact\"], axis = 1) #Independant \n",
                "y_train = train_data[\"y_fact\"] #Dependant\n",
                "\n",
                "X_test = test_data.drop([\"y_fact\"], axis = 1) #Independant \n",
                "y_test = test_data[\"y_fact\"] #Dependant"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After dividing the data, we train the model with it and then predict with it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a function to check the metrics of the algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_metrics(y_train, y_test, y_pred_train, y_pred_test):\n",
                "    # Metrics for training dataset\n",
                "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
                "    train_f1 = f1_score(y_train, y_pred_train)\n",
                "    train_auc = roc_auc_score(y_train, y_pred_train)\n",
                "    train_precision = precision_score(y_train, y_pred_train)\n",
                "    train_recall = recall_score(y_train, y_pred_train)\n",
                "    train_specificity = specificity_score(y_train, y_pred_train)\n",
                "\n",
                "    # Metrics for test dataset \n",
                "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
                "    test_f1 = f1_score(y_test, y_pred_test)\n",
                "    test_auc = roc_auc_score(y_test, y_pred_test)\n",
                "    test_precision = precision_score(y_test, y_pred_test)\n",
                "    test_recall = recall_score(y_test, y_pred_test)\n",
                "    test_specificity = specificity_score(y_test, y_pred_test)\n",
                "\n",
                "    # Calculate difference of train againts test dataset\n",
                "    diff_accuracy = train_accuracy - test_accuracy\n",
                "    diff_f1 = train_f1 - test_f1\n",
                "    diff_auc = train_auc - test_auc\n",
                "    diff_precision = train_precision - test_precision\n",
                "    diff_recall = train_recall - test_recall\n",
                "    diff_specificity = train_specificity - test_specificity\n",
                "\n",
                "    # Crear un DataFrame con los resultados\n",
                "    metrics_df = pd.DataFrame([[train_accuracy, train_f1, train_auc, train_precision, train_recall, train_specificity],[test_accuracy, test_f1, test_auc, test_precision, test_recall, test_specificity],[diff_accuracy, diff_f1, diff_auc, diff_precision, diff_recall, diff_specificity]],\n",
                "                              columns = ['Accuracy', 'F1', 'AUC', 'Precision', 'Recall', 'Specificity'],\n",
                "                              index = ['Train','Test', 'Differs'])\n",
                "\n",
                "    return metrics_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>F1</th>\n",
                            "      <th>AUC</th>\n",
                            "      <th>Precision</th>\n",
                            "      <th>Recall</th>\n",
                            "      <th>Specificity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Train</th>\n",
                            "      <td>0.905100</td>\n",
                            "      <td>0.418959</td>\n",
                            "      <td>0.643633</td>\n",
                            "      <td>0.658294</td>\n",
                            "      <td>0.307252</td>\n",
                            "      <td>0.980015</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Test</th>\n",
                            "      <td>0.898373</td>\n",
                            "      <td>0.405962</td>\n",
                            "      <td>0.636810</td>\n",
                            "      <td>0.652968</td>\n",
                            "      <td>0.294542</td>\n",
                            "      <td>0.979078</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Differs</th>\n",
                            "      <td>0.006727</td>\n",
                            "      <td>0.012997</td>\n",
                            "      <td>0.006824</td>\n",
                            "      <td>0.005326</td>\n",
                            "      <td>0.012710</td>\n",
                            "      <td>0.000937</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         Accuracy        F1       AUC  Precision    Recall  Specificity\n",
                            "Train    0.905100  0.418959  0.643633   0.658294  0.307252     0.980015\n",
                            "Test     0.898373  0.405962  0.636810   0.652968  0.294542     0.979078\n",
                            "Differs  0.006727  0.012997  0.006824   0.005326  0.012710     0.000937"
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Using simple filter to disguise convergence warnings\n",
                "simplefilter(\"ignore\")\n",
                "\n",
                "#Create the logistic regression model\n",
                "model = LogisticRegression()\n",
                "\n",
                "#Train the logistic regression model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "#Predict using the trained model and use the metrics function to retrieve valuable information\n",
                "#Test variables\n",
                "y_pred_test = model.predict(X_test)\n",
                "\n",
                "#Train variables\n",
                "y_pred_train = model.predict(X_train)\n",
                "\n",
                "get_metrics(y_train, y_test, y_pred_train, y_pred_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now to optimize the model we will use GridSearch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
                    ]
                }
            ],
            "source": [
                "# We define the parameters that we want to adjust\n",
                "hyperparams = {\n",
                "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
                "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
                "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
                "}\n",
                "\n",
                "# We initialize the GridSearch\n",
                "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 10)\n",
                "\n",
                "#Fit the GridSearch with train data\n",
                "grid.fit(X_train, y_train)\n",
                "\n",
                "#Print the best parameters\n",
                "print(grid.best_params_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>F1</th>\n",
                            "      <th>AUC</th>\n",
                            "      <th>Precision</th>\n",
                            "      <th>Recall</th>\n",
                            "      <th>Specificity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Train</th>\n",
                            "      <td>0.905950</td>\n",
                            "      <td>0.447378</td>\n",
                            "      <td>0.659254</td>\n",
                            "      <td>0.647059</td>\n",
                            "      <td>0.341876</td>\n",
                            "      <td>0.976633</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Test</th>\n",
                            "      <td>0.899223</td>\n",
                            "      <td>0.430727</td>\n",
                            "      <td>0.649783</td>\n",
                            "      <td>0.644764</td>\n",
                            "      <td>0.323378</td>\n",
                            "      <td>0.976187</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Differs</th>\n",
                            "      <td>0.006727</td>\n",
                            "      <td>0.016651</td>\n",
                            "      <td>0.009472</td>\n",
                            "      <td>0.002295</td>\n",
                            "      <td>0.018498</td>\n",
                            "      <td>0.000446</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         Accuracy        F1       AUC  Precision    Recall  Specificity\n",
                            "Train    0.905950  0.447378  0.659254   0.647059  0.341876     0.976633\n",
                            "Test     0.899223  0.430727  0.649783   0.644764  0.323378     0.976187\n",
                            "Differs  0.006727  0.016651  0.009472   0.002295  0.018498     0.000446"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Create the logistic regression model again, this time with the hyperparameters used for optimization\n",
                "model = LogisticRegression(C= 1000, penalty= 'l2', solver= 'lbfgs')\n",
                "\n",
                "#Train the logistic regression model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "#Predict using the trained model and use the metrics function to retrieve valuable information\n",
                "#Test variables\n",
                "y_pred_test = model.predict(X_test)\n",
                "\n",
                "#Train variables\n",
                "y_pred_train = model.predict(X_train)\n",
                "\n",
                "get_metrics(y_train, y_test, y_pred_train, y_pred_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model accuracy is improved."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we use pickle to dump our model to the models folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "dump(model, open(\"../models/logistic_regression_C-0.1_penalty-l2_solver-liblinear_42.sav\", \"wb\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
