{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.feature_selection import SelectKBest, chi2\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score\n",
                "import numpy as np\n",
                "from pickle import dump\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We need to perform an EDA before modeling, in this exercise I will cover only the basics since the algorithm is the main point."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Collect the data "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(41188, 21)"
                        ]
                    },
                    "execution_count": 217,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv\", sep= \";\")\n",
                "\n",
                "all_data.head()\n",
                "all_data.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now delete all possible duplicates in this dataset, in case there are. Also, obtain the null values and information as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 41176 entries, 0 to 41175\n",
                        "Data columns (total 21 columns):\n",
                        " #   Column          Non-Null Count  Dtype  \n",
                        "---  ------          --------------  -----  \n",
                        " 0   age             41176 non-null  int64  \n",
                        " 1   job             41176 non-null  object \n",
                        " 2   marital         41176 non-null  object \n",
                        " 3   education       41176 non-null  object \n",
                        " 4   default         41176 non-null  object \n",
                        " 5   housing         41176 non-null  object \n",
                        " 6   loan            41176 non-null  object \n",
                        " 7   contact         41176 non-null  object \n",
                        " 8   month           41176 non-null  object \n",
                        " 9   day_of_week     41176 non-null  object \n",
                        " 10  duration        41176 non-null  int64  \n",
                        " 11  campaign        41176 non-null  int64  \n",
                        " 12  pdays           41176 non-null  int64  \n",
                        " 13  previous        41176 non-null  int64  \n",
                        " 14  poutcome        41176 non-null  object \n",
                        " 15  emp.var.rate    41176 non-null  float64\n",
                        " 16  cons.price.idx  41176 non-null  float64\n",
                        " 17  cons.conf.idx   41176 non-null  float64\n",
                        " 18  euribor3m       41176 non-null  float64\n",
                        " 19  nr.employed     41176 non-null  float64\n",
                        " 20  y               41176 non-null  object \n",
                        "dtypes: float64(5), int64(5), object(11)\n",
                        "memory usage: 6.6+ MB\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(41176, 21)"
                        ]
                    },
                    "execution_count": 218,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_data = all_data.drop_duplicates().reset_index(drop= True)\n",
                "\n",
                "all_data.info()\n",
                "all_data.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There aren't any null values but some duplicates, in this case, 12 duplicates.\n",
                "\n",
                "Also, with the .info method we can know that there aren't any null values in this dataset.\n",
                "\n",
                "We need to also factorize all the categorical variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Factorize categorical variables in a new dataframe\n",
                "all_data[\"job_fact\"] = pd.factorize(all_data[\"job\"])[0]\n",
                "all_data[\"marital_fact\"] = pd.factorize(all_data[\"marital\"])[0]\n",
                "all_data[\"education_fact\"] = pd.factorize(all_data[\"education\"])[0]\n",
                "all_data[\"default_fact\"] = pd.factorize(all_data[\"default\"])[0]\n",
                "all_data[\"housing_fact\"] = pd.factorize(all_data[\"housing\"])[0]\n",
                "all_data[\"loan_fact\"] = pd.factorize(all_data[\"loan\"])[0]\n",
                "all_data[\"contact_fact\"] = pd.factorize(all_data[\"contact\"])[0]\n",
                "all_data[\"month_fact\"] = pd.factorize(all_data[\"month\"])[0]\n",
                "all_data[\"day_of_week_fact\"] = pd.factorize(all_data[\"day_of_week\"])[0]\n",
                "all_data[\"poutcome_fact\"] = pd.factorize(all_data[\"poutcome\"])[0]\n",
                "all_data[\"y_fact\"] = pd.factorize(all_data[\"y\"])[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Scale all the data and divide the data into train and test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>job_fact</th>\n",
                            "      <th>marital_fact</th>\n",
                            "      <th>education_fact</th>\n",
                            "      <th>default_fact</th>\n",
                            "      <th>housing_fact</th>\n",
                            "      <th>loan_fact</th>\n",
                            "      <th>contact_fact</th>\n",
                            "      <th>month_fact</th>\n",
                            "      <th>day_of_week_fact</th>\n",
                            "      <th>poutcome_fact</th>\n",
                            "      <th>...</th>\n",
                            "      <th>duration</th>\n",
                            "      <th>campaign</th>\n",
                            "      <th>pdays</th>\n",
                            "      <th>previous</th>\n",
                            "      <th>emp.var.rate</th>\n",
                            "      <th>cons.price.idx</th>\n",
                            "      <th>cons.conf.idx</th>\n",
                            "      <th>euribor3m</th>\n",
                            "      <th>nr.employed</th>\n",
                            "      <th>y_fact</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.053070</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.9375</td>\n",
                            "      <td>0.698753</td>\n",
                            "      <td>0.60251</td>\n",
                            "      <td>0.957379</td>\n",
                            "      <td>0.859735</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.090909</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.142857</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.030297</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.9375</td>\n",
                            "      <td>0.698753</td>\n",
                            "      <td>0.60251</td>\n",
                            "      <td>0.957379</td>\n",
                            "      <td>0.859735</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.090909</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.142857</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.045954</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.9375</td>\n",
                            "      <td>0.698753</td>\n",
                            "      <td>0.60251</td>\n",
                            "      <td>0.957379</td>\n",
                            "      <td>0.859735</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.181818</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.285714</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.030704</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.9375</td>\n",
                            "      <td>0.698753</td>\n",
                            "      <td>0.60251</td>\n",
                            "      <td>0.957379</td>\n",
                            "      <td>0.859735</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.090909</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.142857</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.062424</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.9375</td>\n",
                            "      <td>0.698753</td>\n",
                            "      <td>0.60251</td>\n",
                            "      <td>0.957379</td>\n",
                            "      <td>0.859735</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 21 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   job_fact  marital_fact  education_fact  default_fact  housing_fact  \\\n",
                            "0  0.000000           0.0        0.000000           0.0           0.0   \n",
                            "1  0.090909           0.0        0.142857           0.5           0.0   \n",
                            "2  0.090909           0.0        0.142857           0.0           0.5   \n",
                            "3  0.181818           0.0        0.285714           0.0           0.0   \n",
                            "4  0.090909           0.0        0.142857           0.0           0.0   \n",
                            "\n",
                            "   loan_fact  contact_fact  month_fact  day_of_week_fact  poutcome_fact  ...  \\\n",
                            "0        0.0           0.0         0.0               0.0            0.0  ...   \n",
                            "1        0.0           0.0         0.0               0.0            0.0  ...   \n",
                            "2        0.0           0.0         0.0               0.0            0.0  ...   \n",
                            "3        0.0           0.0         0.0               0.0            0.0  ...   \n",
                            "4        0.5           0.0         0.0               0.0            0.0  ...   \n",
                            "\n",
                            "   duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
                            "0  0.053070       0.0    1.0       0.0        0.9375        0.698753   \n",
                            "1  0.030297       0.0    1.0       0.0        0.9375        0.698753   \n",
                            "2  0.045954       0.0    1.0       0.0        0.9375        0.698753   \n",
                            "3  0.030704       0.0    1.0       0.0        0.9375        0.698753   \n",
                            "4  0.062424       0.0    1.0       0.0        0.9375        0.698753   \n",
                            "\n",
                            "   cons.conf.idx  euribor3m  nr.employed  y_fact  \n",
                            "0        0.60251   0.957379     0.859735     0.0  \n",
                            "1        0.60251   0.957379     0.859735     0.0  \n",
                            "2        0.60251   0.957379     0.859735     0.0  \n",
                            "3        0.60251   0.957379     0.859735     0.0  \n",
                            "4        0.60251   0.957379     0.859735     0.0  \n",
                            "\n",
                            "[5 rows x 21 columns]"
                        ]
                    },
                    "execution_count": 220,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "num_variables = [\"job_fact\", \"marital_fact\", \"education_fact\", \"default_fact\", \"housing_fact\", \"loan_fact\", \"contact_fact\", \"month_fact\", \"day_of_week_fact\", \"poutcome_fact\",\n",
                "                 \"age\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\", \"y_fact\"]\n",
                "\n",
                "scaler = MinMaxScaler()\n",
                "scal_features = scaler.fit_transform(all_data[num_variables])\n",
                "fact_data_scal = pd.DataFrame(scal_features, index = all_data.index, columns = num_variables)\n",
                "\n",
                "X = fact_data_scal.drop([\"y_fact\"], axis= 1) #Independant variables\n",
                "y = fact_data_scal[\"y_fact\"]# Dependant variables, target\n",
                "\n",
                "#Now using train_test_split from sklearn, we separate the variables. Ones are going to be used for training the algorithm and the others to test the algorithm\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42) #Random state controls how many shuffles is applied to the data before spliting. It's the same number to replicate the same experiment\n",
                "\n",
                "fact_data_scal.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Feature selection with SelectKBest using a chi2 statistical method"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 221,
            "metadata": {},
            "outputs": [],
            "source": [
                "#We create the selection model, in this case k is the number of features to be selected and chi2 the method used to determine wich are the best features to include\n",
                "selection_model = SelectKBest(chi2, k = 5)\n",
                "\n",
                "#Fit the model with both X_train and y_train\n",
                "selection_model.fit(X_train, y_train)\n",
                "\n",
                "#Gets an array of the features selected\n",
                "ix = selection_model.get_support()\n",
                "\n",
                "#With ix we convert that array information into two new datasets that contain the features selected\n",
                "X_train_features = pd.DataFrame(selection_model.transform(X_train), columns = X_train.columns.values[ix])\n",
                "X_test_features = pd.DataFrame(selection_model.transform(X_test), columns = X_test.columns.values[ix])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save the new data to proceed with the exercise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_features[\"y_fact\"] = list(y_train)\n",
                "X_test_features[\"y_fact\"] = list(y_test)\n",
                "X_train_features.to_csv(\"../data/processed/clean_train.csv\", index = False)\n",
                "X_test_features.to_csv(\"../data/processed/clean_test.csv\", index = False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we continue with the Logistic Regression Model. For that we need to read the data that we saved later and then divide it again into X and y, those are going to be our independant and dependant data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 223,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Read the data saved\n",
                "train_data = pd.read_csv(\"../data/processed/clean_train.csv\")\n",
                "test_data = pd.read_csv(\"../data/processed/clean_test.csv\")\n",
                "\n",
                "#Divide into train and test for each independant and dependant variables\n",
                "X_train = train_data.drop([\"y_fact\"], axis = 1) #Independant \n",
                "y_train = train_data[\"y_fact\"] #Dependant\n",
                "\n",
                "X_test = test_data.drop([\"y_fact\"], axis = 1) #Independant \n",
                "y_test = test_data[\"y_fact\"] #Dependant"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After dividing the data, we train the model with it and then predict with it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8886595434677028"
                        ]
                    },
                    "execution_count": 224,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Create the logistic regression model\n",
                "model = LogisticRegression()\n",
                "\n",
                "#Train the logistic regression model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "#Predict using the trained model and use the accuracy score to the determine it's precission\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now to optimize the model we will use GridSearch. Tried to use RandomSearchCV but pops a lot of unexpected errors and I don't really know how to handle them"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
                    ]
                }
            ],
            "source": [
                "# We define the parameters that we want to adjust\n",
                "hyperparams = {\n",
                "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
                "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
                "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
                "}\n",
                "\n",
                "# We initialize the GridSearch\n",
                "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 10)\n",
                "\n",
                "#Fit the GridSearch with train data\n",
                "grid.fit(X_train, y_train)\n",
                "\n",
                "#Print the best parameters, will be {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'} in this case\n",
                "print(grid.best_params_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8901165614375911"
                        ]
                    },
                    "execution_count": 226,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Create the logistic regression model again, this time with the hyperparameters used for optimization\n",
                "model = LogisticRegression(C= 0.1, penalty= 'l2', solver= 'newton-cg')\n",
                "\n",
                "#Train the logistic regression model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "#Predict using the trained model and use the accuracy score to the determine it's precission\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model accuracy goes from 0.8886595434677028 to 0.8901165614375911 so we succesfully optimize it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we use pickle to dump our model to the models folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "metadata": {},
            "outputs": [],
            "source": [
                "dump(model, open(\"../models/logistic_regression_C-0.1_penalty-l2_solver-liblinear_42.sav\", \"wb\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
